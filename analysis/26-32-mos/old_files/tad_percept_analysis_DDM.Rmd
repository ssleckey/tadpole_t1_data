---
title: "Toddler Uncertainty Monitoring"
author: "Emily"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    number_sections: true
---

<style type="text/css">
body, td {
   font-size: 14px;
}
code {
  font-size: 11px;
}
pre {
  font-size: 11px;
}
</style>

Data analysis of toddler uncertainty monitoring study.

# Data preprocessing

Preliminaries.

```{r, include = FALSE}
setwd("~/Desktop/tadpole_t1_data/analysis/26-32-mos/")
rm(list=ls())
knitr::opts_chunk$set(fig.width=8, fig.height=5, 
                      echo=TRUE, warning=FALSE, message=FALSE, cache=TRUE)
suppressPackageStartupMessages(c("dplyr","langcog","tidyr","ggplot2","lme4"))
library(langcog)
library(plyr)
library(dplyr)
library(RWiener)
library(ggplot2)
library(rjson)
library(stringr)
library(tidyr)
library(lme4)
library(xtable)
library(knitr)
library(markdown)
library(psych)
library(Hmisc)
library(magrittr)

theme_set(theme_bw())
```

Read in trial info, demographics, and word familiarity.

```{r}
demo <- read.csv("demographics.csv") 
trial_info <- read.csv("conditions.csv", header = TRUE)
trial_info$trial <- as.character(trial_info$trial)

word_fam_key <- read.csv("word_fam_key.csv")
word_fam_key$trial <- as.character(word_fam_key$trial)

word_fam <- read.csv("word_familiarity.csv") %>%
  gather("target", "familiarity", 2:41 )

response_key <- read.csv("response_key.csv")
response_key$trial <- as.character(response_key$trial)
```

Read in TS data file.

```{r}
d.raw_ts <- read.table("AllSubs_TS.txt", header = TRUE) 
```

Make TS data tidy.

```{r}
d_acc_ts<- d.raw_ts %>%
  select(Subject_ID, acc1, acc2, acc3, acc4, acc5, acc6, acc7, acc8, acc9, acc10, acc11, acc12, acc13, acc14, acc15, acc16, acc17, acc18, acc19, acc20)%>%
  gather(trial, acc, acc1:acc20) 

d_rt <- d.raw_ts %>%
  select(Subject_ID, RT1, RT2, RT3, RT4, RT5, RT6, RT7, RT8, RT9, RT10, RT11, RT12, RT13, RT14, RT15, RT16, RT17, RT18, RT19, RT20) %>%
  gather(trial, RT, RT1:RT20) 

d_acc_ts$trial <-str_replace(d_acc_ts$trial, "acc","")
d_rt$trial <- str_replace(d_rt$trial, "RT","")

d_ts <- d_acc_ts %>%
  left_join(d_rt) %>%
  mutate(ID = Subject_ID) %>%
  select(ID, RT, acc, trial)

d_ts$acc[d_ts$acc==999] <- NA
```

Join trial info and demographics with raw TS data.

```{r}
d_ts <- d_ts %>%
  left_join(trial_info) %>%
  left_join(demo) %>%
  select(-participation_date, -birthdate) %>%
  left_join(word_fam_key) %>%
  left_join(word_fam) %>%
  left_join(response_key) %>%
  filter(drop != 1) %>%
  group_by(ID) %>%
    mutate(avg_acc = mean(acc, na.rm = TRUE))%>%
  filter(avg_acc > .50) 

d_ts <- d_ts %>% 
  mutate(similar = ifelse(similarity == 1, "similar",
                                       "dissimilar")) %>%
  select(-similarity)
```


```{r}
d_ts$ID <- as.factor(as.character(d_ts$ID))
length(levels(d_ts$ID))
```
There are `r length(levels(d_ts$ID))` touchscreen participants.

Read in ET data. 

```{r}
d.raw_et <- read.csv("AllSubs_ET.csv", header = TRUE) 
d.raw_sw <- read.csv("perceptual_transitions.csv", header = TRUE)
d.raw_sw$ID <- d.raw_sw$Subject
```

Make data ET tidy and join trial info and demographics with raw data.

```{r}
d.raw_sw <- d.raw_sw %>%
  gather(trial, trans, Trial1:Trial20) %>%
  select(-Subject) 
```

```{r}
d.raw_sw$ID <- as.factor(as.character(d.raw_sw$ID))
length(levels(d.raw_sw$ID))
```
There are `r length(levels(d.raw_sw$ID))` eyetracker participants with transitions data including pilots and others to-be-excluded.

```{r}
d.raw_et$ID <- as.factor(as.character(d.raw_et$ID))
length(levels(d.raw_et$ID))
```
There are `r length(levels(d.raw_et$ID))` eyetracker participants with accuracy data including pilots and others to-be-excluded.

Join ET transitions and accuracy data and drop excluded participants (including pilots).

```{r}
d.raw_sw$trial <- str_replace(d.raw_sw$trial, "Trial","")
d.raw_et$trial <- as.character(d.raw_et$trial)

d.raw_et <- d.raw_et %>%
  select(ID, trial, acc)

d.raw_sw$ID <- as.character(d.raw_sw$ID)
d.raw_et$ID <- as.character(d.raw_et$ID)
demo$ID <- as.character(demo$ID)
word_fam$ID <- as.character(word_fam$ID)

d_et <- d.raw_et %>%
  inner_join(d.raw_sw) %>%
  mutate(acc_et = acc) %>%
  left_join(demo) %>%
  left_join(trial_info)%>%
  select(-participation_date, -birthdate) %>%
  left_join(word_fam_key) %>%
  left_join(word_fam) %>%
  left_join(response_key) %>%
  filter(drop != 1) %>%
  select(-acc)  %>%
  group_by(ID) %>%
  mutate(avg_acc = mean(acc_et, na.rm = TRUE))%>%
  filter(avg_acc > .50) 

d_et <- d_et %>% 
  mutate(similar = ifelse(similarity == 1, "similar",
                                       "dissimilar")) %>%
  select(-similarity)
```

```{r}
d_et$ID <- as.factor(as.character(d_et$ID))
length(levels(d_et$ID))
```

There are `r length(levels(d_et$ID))` eyetracker participants with both transitions and accuracy data.

Merge TS and ET data and drop excluded participants (including pilots).

```{r}
d <- d_ts %>%
  full_join(d_et) %>%
  filter(drop != 1) 

write.table(d_ts, file = "ts.csv", sep = ",", col.names = NA,
            qmethod = "double")

write.table(d_et, file = "et.csv", sep = ",", col.names = NA,
            qmethod = "double")

write.table(d, file = "d.csv", sep = ",", col.names = NA,
            qmethod = "double")

```

```{r}
d$ID <- as.factor(as.character(d$ID))
length(levels(d$ID))
```

There are `r length(levels(d$ID))` participants with *either* eyetracker or touchscreen data.


Filter missing data and unfamiliar trials in ET data.

```{r}
d_et_filt <- d_et %>% 
  filter(!is.na(trans),
         !is.na(acc_et),
         familiarity != 0) %>%
  group_by(ID) %>%
  mutate(avg_acc = mean(acc_et))
```

Filter fast and slow RTs, missing data, unfamiliar trials in RT data.

```{r}
top_bound <- mean(log(d_ts$RT)) + 3*sd(log(d_ts$RT))
bottom_bound <- mean(log(d_ts$RT)) - 3*sd(log(d_ts$RT))

d_filt_rt <- d_ts %>%
  filter(log(RT) < top_bound, 
         log(RT) > bottom_bound,
         !is.na(acc),
         familiarity != 0)

d_filt_rt <- d_filt_rt %>%
  group_by(ID)%>%
  mutate(RT = log(RT))
```

#Demographics

```{r, include = FALSE}
demo_drop <- demo %>%
  filter(drop != 1)

demo_drop$income <- str_replace(demo_drop$income,"f ","f")

demo_drop$income <- str_replace(demo_drop$income,"a","<15,000")
demo_drop$income <- str_replace(demo_drop$income,"b","15,000-25,000")
demo_drop$income <- str_replace(demo_drop$income,"c","25,000-40,000")
demo_drop$income <- str_replace(demo_drop$income,"d","40,000-60,000")
demo_drop$income <- str_replace(demo_drop$income,"e","60,000-90,000")
demo_drop$income <- str_replace(demo_drop$income,"f",">90,000")

demo_drop$income <- factor(demo_drop$income, levels = c("","<15,000","15,000-25,000","25,000-40,000","40,000-60,000","60,000-90,000",">90,000"))
```

```{r}
summary(demo_drop$income)
summary(demo_drop$race)
summary(demo_drop$gender)
psych::describe(demo_drop$age_months)

```

#Accuracy

```{r, echo=FALSE}
d_compare <- d %>%
  select(ID, trial, similar, acc, acc_et, familiarity, age_months, target) %>%
  filter(familiarity != 0) %>%
  gather(task, acc, acc:acc_et) 

levels(d_compare$task) <- list(touchscreen="acc", eyetracker="acc_et")
d_compare$acc <- as.numeric(d_compare$acc)

ms <- d_compare %>%
  group_by(similar, task)%>%
  multi_boot_standard(col = "acc", na.rm = TRUE)

ggplot(ms, aes(x = factor(similar), y = mean, fill = similar)) + geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
             position = position_dodge(width = .9)) +
  xlab("Similarity") + 
  ylab("Proportion Accurate") + 
  facet_wrap(~task, labeller = label_both)
```

Get mean accuracy by task and similarity.
```{r}
d_acc_et <- d_compare %>%
  filter(task == "eyetracker")
d_acc_ts <- d_compare %>%
  filter(task == "touchscreen")
```

Accuracy for eyetracker
```{r}
psych::describeBy(d_acc_et$acc, d_acc_et$similar)
```

Accuracy t-tests

```{r}
d_et_acc_t <- d_et_filt %>%
  select(ID, trial, acc_et, similar) %>%
  group_by(ID, similar) %>%
  summarise(acc_et = mean(acc_et)) %>%
  spread(similar, acc_et) 

# paired t-test
test_acc_et <- t.test(d_et_acc_t$similar, d_et_acc_t$dissimilar,paired=TRUE) 
test_acc_et

d_ts_acc_t <- d_filt_rt %>%
  select(ID, trial, acc, similar) %>%
  group_by(ID, similar) %>%
  summarise(acc = mean(acc)) %>%
  spread(similar, acc)

# paired t-test
test_acc_ts <- t.test(d_ts_acc_t$similar, d_ts_acc_t$dissimilar,paired=TRUE) 
test_acc_ts
```

Accuracy for dissimilar items is higher for both the eyetracker task (*t* = `r round(test_acc_et$statistic, digits = 2)`, *p* = `r round(test_acc_et$p.value, digits = 2)`) and the touchscreen task (*t* = `r round(test_acc_ts$statistic, digits = 2)`, *p* = `r round(test_acc_ts$p.value, digits = 2)`)

Accuracy for touchscreen
```{r}
psych::describeBy(d_acc_ts$acc, d_acc_ts$similar)
```

#Eyetracker data

Plot distribution (density) of transitions (switches) by accuracy and similarity.

```{r, echo=FALSE}
d_et_filt$acc <- as.factor(d_et_filt$acc)

ggplot(aes(x = trans, fill = acc), 
       data = d_et_filt) +
  geom_density(alpha = 0.7, adjust = 1.5) + 
  facet_grid(.~similar) 
```

Plot proportion accurate by similarity.

```{r, echo=FALSE}
d_et_filt$acc <- as.numeric(d_et_filt$acc)

ms <- d_et_filt %>%
  group_by(similar)%>%
  multi_boot_standard(col = "acc_et", na.rm = TRUE)

ggplot(ms, aes(x = factor(similar), y = mean, fill = similar)) + geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
             position = position_dodge(width = .9)) +
  xlab("Similarity") + 
  ylab("Proportion Accurate ET")
```

Plot the mean number of transitions (switches) by accuracy and similarity.

```{r, echo=FALSE}
d_et_filt$acc_et <- as.factor(as.character(d_et_filt$acc_et))

ms <- d_et_filt %>%
  group_by(acc_et, similar)%>%
  multi_boot_standard(col = "trans", na.rm = TRUE)

ggplot(ms, aes(x = factor(acc_et), y = mean, fill = acc_et)) + geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
             position = position_dodge(width = .9)) +
  xlab("Accuracy") + 
  ylab("Number of switches") + 
  facet_wrap(~similar)
```

##Analyses

Linear mixed-effects models predicting switch count based on similarity and accuracy.

```{r}
#more complex random effects structures fail to converge.
#expect random effects slopes to vary more for ID than target- effects of similarity and accuracy should vary more by participant than target.

glm_trans_full <- lmer(trans ~ similar + acc +
                          (similar + acc | ID) + (1 | target), 
                         data = d_et_filt, REML = FALSE)

glm_trans_interaction <- lmer(trans ~ similar * acc +
                          (similar + acc | ID) + (1 | target), 
                         data = d_et_filt, REML = FALSE)

glm_trans_sim <- lmer(trans ~ similar +
                          (similar + acc | ID) + (1 | target), 
                         data = d_et_filt, REML = FALSE)

glm_trans_acc <- lmer(trans ~ acc +
                          (similar + acc | ID) + (1 | target), 
                         data = d_et_filt, REML = FALSE)
```

Summary of maximal model (without interaction term).
```{r}
summary(glm_trans_full)
```

Fixed effects coeffiencients for full model.
```{r, echo = FALSE}
kable(summary(glm_trans_full)$coefficients, digits = 2)
```

Compare model fits as significance test.

Test for effect of accuracy.
```{r, echo=FALSE}
kable(anova(glm_trans_full, glm_trans_sim))
```

Test for effect of similarity.
```{r, echo=FALSE}
kable(anova(glm_trans_full, glm_trans_acc))

sim_effect <- anova(glm_trans_full, glm_trans_acc)
sim_effect$p <- as.numeric(sim_effect$`Pr(>Chisq)`[2])
```

Test for effect of interaction between accuracy and similarity.

```{r, echo=FALSE}
kable(anova(glm_trans_full, glm_trans_interaction))
```

Similarity affected switch count (*χ2(1)*=`r round(sim_effect$Chisq[2], digits = 2)`, *p*=`r round(sim_effect$p[1], digits = 2)`)
, such that similarity (compared to dissimilarity) added `r round(summary(glm_trans_full)$coefficients[2], digits = 2)` (SE = `r round(summary(glm_trans_full)$coefficients[5], digits = 2)`) switches. Accuracy was not a significant predictor, and accuracy and similarity did not interact.

Get mean transitions by similarity and accuracy.
```{r}
describeBy(d_et_filt$trans, d_et_filt$similar)
describeBy(d_et_filt$trans, d_et_filt$acc_et)
```

Accuracy and similarity are correlated. Let's look at the similarity effect separately for accurate and inaccurate trials. To do this we will conduct a paired-samples t-test on the average number of transitions for similar vs. dissimilar trials, first for the accurate trials, and then for the inaccurate trials.

```{r}
#accurate trials
d_et_filt_t <- filter(d_et_filt, acc_et == "1") %>%
  select(ID, trial, trans, similar) %>%
  group_by(ID, similar) %>%
  summarise(trans = mean(trans)) %>%
  spread(similar, trans)
  
# paired t-test
test_acc <- t.test(d_et_filt_t$similar, d_et_filt_t$dissimilar,paired=TRUE) 
test_acc

#inaccurate trials
d_et_filt_t <- filter(d_et_filt, acc_et == "0") %>%
  select(ID, trial, trans, similar) %>%
  group_by(ID, similar) %>%
  summarise(trans = mean(trans)) %>%
  spread(similar, trans)
  
# paired t-test
test_inacc <- t.test(d_et_filt_t$similar, d_et_filt_t$dissimilar,paired=TRUE) 
test_inacc

#inaccurate trials
d_et_filt_t <- d_et_filt %>%
  select(ID, trial, trans, acc_et) %>%
  group_by(ID, acc_et) %>%
  summarise(trans = mean(trans))

levels(d_et_filt_t$acc_et) <- list(acc="1", inacc="0") 
    
d_et_filt_t <- d_et_filt_t %>%
  spread(acc_et, trans)
  
# paired t-test
test_inacc <- t.test(d_et_filt_t$acc, d_et_filt_t$inacc, paired=TRUE) 
test_inacc
```

The effect of similarity was significant among accurate trials, *t* = `r round(test_acc$statistic, digits = 2)`, *p* = `r round(test_acc$p.value, digits = 2)`, but not inaccurate trials, *t* = `r round(test_inacc$statistic, digits = 2)`, *p* = `r round(test_inacc$p.value, digits = 2)`.

Do individual differences in RT differential (for similar vs. dissimilar) correlate with accuracy? 

```{r}
d_et_filt$acc_et <- as.numeric(as.character(d_et_filt$acc_et))

d_et_filt_id <- d_et_filt %>%
  group_by(ID) %>%
  mutate(avg_acc = mean(acc_et)) %>%
  mutate(trans_acc = mean(trans[acc_et == 1])) %>%
  mutate(trans_inacc = mean(trans[acc_et == 0])) %>%
  mutate(trans_sim = mean(trans[similar == "similar"])) %>%
  mutate(trans_dissim = mean(trans[similar == "dissimilar"])) %>%
  mutate(trans_acc_diff = trans_inacc - trans_acc) %>%
  mutate(trans_sim_diff = trans_sim - trans_dissim) %>%
  mutate(avg_acc = mean(acc_et)) %>%
  mutate(avg_trans_acc = mean(trans[acc_et == 1])) %>%
  mutate(avg_trans_inacc = mean(trans[acc_et == 0])) %>%
  mutate(trans_dissim_acc = mean(trans[similar == "dissimilar" & acc_et == 1])) %>%
  mutate(trans_sim_acc = mean(trans[similar == "similar" & acc_et == 1])) %>%
  mutate(trans_dissim_inacc = mean(trans[similar == "dissimilar" & acc_et == 0])) %>%
  mutate(trans_sim_inacc = mean(trans[similar == "similar" & acc_et == 0]))
```

```{r, echo=FALSE}
ggplot(aes(x = trans_acc_diff), 
       data = d_et_filt_id) +
  geom_density(alpha = 0.7, adjust = 1.5)

ggplot(aes(x = trans_sim_diff), 
       data = d_et_filt_id) +
  geom_density(alpha = 0.7, adjust = 1.5)
```

Correlate differentials with accuracy.

```{r}
d_et_filt_id <- d_et_filt_id %>%
  select(ID, avg_acc, trans_acc_diff, trans_sim_diff, trans_dissim_acc, trans_sim_acc, trans_dissim_inacc, trans_sim_inacc) %>%
  distinct %>%
  ungroup %>%
  select(-ID)

tr_corr <- rcorr(as.matrix(d_et_filt_id), type = "pearson")
tr_corr
tr_corr_n <- sqrt(length(tr_corr$P)) - 1

p.adjust(tr_corr$P[2:tr_corr_n], method = "bonferroni", n = tr_corr_n)

#p.adjust.methods
# c("holm", "hochberg", "hommel", "bonferroni", "BH", "BY",
#   "fdr", "none")
```

```

```{r, include = FALSE}
corstarsl <- function(x){ 
  require(Hmisc) 
  x <- as.matrix(x) 
  R <- rcorr(x)$r 
  p <- rcorr(x)$P 
  
  ## define notions for significance levels; spacing is important.
  mystars <- ifelse(p < .001, "***", ifelse(p < .01, "** ", ifelse(p < .05, "* ", " ")))
  
  ## trunctuate the matrix that holds the correlations to two decimal
  R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1] 
  
  ## build a new matrix that includes the correlations with their apropriate stars 
  Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x)) 
  diag(Rnew) <- paste(diag(R), " ", sep="") 
  rownames(Rnew) <- colnames(x) 
  colnames(Rnew) <- paste(colnames(x), "", sep="") 
  
  ## remove upper triangle
  Rnew <- as.matrix(Rnew)
  Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
  Rnew <- as.data.frame(Rnew) 
  
  ## remove last column and return the matrix (which is now a data frame)
  Rnew <- cbind(Rnew[1:length(Rnew)-1])
  return(Rnew) 
}
```

Correlation matrix for individual differences in transitions differentials and accuracy.
```{r}
corstarsl(d_et_filt_id)
```

Individual differences in transitions differentials (i.e., transitions for similar - similar; trans for inacc - acc) were correlated with each other but not with accuracy. 

##Summary of Eyetracker Results

Accuracy was higher for dissimilar items.

Similarity affected switch count (χ2(1)=`r round(sim_effect$Chisq[2], digits = 2)`, p=`r round(sim_effect$p[1], digits = 2)`)
, such that similarity (compared to dissimilarity) added `r round(summary(glm_trans_full)$coefficients[2], digits = 2)` (SE = `r round(summary(glm_trans_full)$coefficients[5], digits = 2)`) switches. Accuracy was not a significant predictor, and accuracy and similarity did not interact.

T-tests showed that the effect of similarity was significant among accurate trials, *t* = `r round(test_acc$statistic, digits = 2)`, *p* = `r round(test_acc$p.value, digits = 2)`, but not inaccurate trials, *t* = `r round(test_inacc$statistic, digits = 2)`, *p* = `r round(test_inacc$p.value, digits = 2)`.

Individual differences in transitions differentials (i.e., transitions for similar - similar; trans for inacc - acc) were correlated with each other but not with accuracy. This is expected as accuracy and similarity are correlated. 

#Touchscreen data.

Plot RT distribution (density) by accuracy and similarity.

```{r, echo=FALSE}
d_filt_rt$acc <- as.factor(d_filt_rt$acc)

ggplot(aes(x = log(RT), fill = acc), 
       data = d_filt_rt) +
  geom_density(alpha = 0.7, adjust = 1.5) + 
  facet_grid(.~similar) 
```

Plot accuracy by similarity. 

```{r, echo=FALSE}
d_filt_rt$acc <- as.numeric(as.character(d_filt_rt$acc))

ms <- d_filt_rt %>%
  filter(!is.na(similar))%>%
  group_by(similar)%>%
  multi_boot_standard(col = "acc", na.rm = TRUE)

ggplot(ms, aes(x = factor(similar), y = mean, fill = similar)) + geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
             position = position_dodge(width = .9)) +
  xlab("Difficulty") + 
  ylab("Proportion Accurate TS")
```

Plot mean RT by accuracy and similarity.

```{r, echo=FALSE}
d_filt_rt$acc <- as.factor(as.character(d_filt_rt$acc))

ms <- d_filt_rt %>%
  filter(!is.na(acc))%>%
  group_by(acc, similar)%>%
  multi_boot_standard(col = "RT", na.rm = TRUE)

ggplot(ms, aes(x = factor(acc), y = mean, fill = acc)) + geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
             position = position_dodge(width = .9)) +
  xlab("Accuracy") + 
  ylab("Mean Reaction Time (ms)") + 
  facet_wrap(~similar, labeller = label_both)
```

##Analyses

Linear mixed-effects models predicting RT based on similarity and accuracy.

```{r}
#more complex random effects structures fail to converge.
#expect random effects slopes to vary more for ID than target- effects of similarity and accuracy should vary more by participant than target.

glm_RT_full <- lmer(RT ~ similar + acc +
                          (similar + acc | ID) + (1 | target), 
                         data = d_filt_rt, REML = FALSE)

glm_RT_interaction <- lmer(RT ~ similar * acc +
                          (similar + acc | ID) + (1 | target), 
                         data = d_filt_rt, REML = FALSE)

glm_RT_sim <- lmer(RT ~ similar +
                          (similar + acc | ID) + (1 | target), 
                         data = d_filt_rt, REML = FALSE)

glm_RT_acc <- lmer(RT ~ acc +
                          (similar + acc | ID) + (1 | target), 
                         data = d_filt_rt, REML = FALSE)
```

Summary of maximal model (without interaction term)
```{r}
summary(glm_RT_full)
```

Fixed effects coeffiencients for full model.
```{r, echo = FALSE}
kable(summary(glm_RT_full)$coefficients, digits = 2)
```

Compare model fits as significance test.

Test for effect of accuracy.
```{r, echo=FALSE}
kable(anova(glm_RT_full, glm_RT_sim))

acc_effect <- anova(glm_RT_full, glm_RT_sim)
acc_effect$p <- as.numeric(acc_effect$`Pr(>Chisq)`[2])
```

Test for effect of similarity.
```{r, echo=FALSE}
kable(anova(glm_RT_full, glm_RT_acc))
```

Test for effect of interaction between accuracy and similarity.
```{r, echo=FALSE}
kable(anova(glm_RT_full, glm_RT_interaction))
```

Accuracy affected switch count (χ2(1)=`r round(acc_effect$Chisq[2], digits = 2)`, p=`r round(acc_effect$p[1], digits = 2)`)
, such that similarity (compared to dissimilarity) added `r round(summary(glm_RT_full)$coefficients[2], digits = 2)` (SE = `r round(summary(glm_RT_full)$coefficients[5], digits = 2)`) switches. Similarity was not a significant predictor, and accuracy and similarity did not interact.

Get mean RT by similarity and accuracy.
```{r}
describeBy(d_filt_rt$RT, d_filt_rt$similar)
describeBy(d_filt_rt$RT, d_filt_rt$acc)
```

Accuracy and similarity are correlated. Let's look at the similarity effect separately for accurate and inaccurate trials. To do this we will conduct a paired-samples t-test on the average number of transitions for similar vs. dissimilar trials, first for the accurate trials, and then for the inaccurate trials.

```{r}
#accurate trials
d_filt_rt_t <- filter(d_filt_rt, acc == "1") %>%
  select(ID, trial, RT, similar) %>%
  group_by(ID, similar) %>%
  summarise(RT = mean(RT)) %>%
  spread(similar, RT)
  
# paired t-test
test_acc <- t.test(d_filt_rt_t$similar, d_filt_rt_t$dissimilar,paired=TRUE) 
test_acc

#inaccurate trials
d_filt_rt_t <- filter(d_filt_rt, acc == "0") %>%
  select(ID, trial, RT, similar) %>%
  group_by(ID, similar) %>%
  summarise(RT = mean(RT)) %>%
  spread(similar, RT)
  
# paired t-test
test_inacc <- t.test(d_filt_rt_t$similar, d_filt_rt_t$dissimilar,paired=TRUE) 
test_inacc
```

The effect of similarity was not significant among accurate trials, *t* = `r round(test_acc$statistic, digits = 2)`, *p* = `r round(test_acc$p.value, digits = 2)`, nor was it significant for inaccurate trials, *t* = `r round(test_inacc$statistic, digits = 2)`, *p* = `r round(test_inacc$p.value, digits = 2)`.

Do individual differences in RT differential (for similar vs. dissimilar) correlate with accuracy? 

```{r}
d_filt_rt$acc <- as.numeric(as.character(d_filt_rt$acc))

d_filt_rt_id <- d_filt_rt %>%
  group_by(ID) %>%
  mutate(rt_acc = mean(RT[acc == 1])) %>%
  mutate(rt_inacc = mean(RT[acc == 0])) %>%
  mutate(avg_rt = mean(RT)) %>%
  mutate(rt_sim = mean(RT[similar == "similar"])) %>%
  mutate(rt_dissim = mean(RT[similar == "dissimilar"])) %>%
  mutate(rt_acc_diff = rt_inacc - rt_acc) %>%
  mutate(rt_sim_diff = rt_sim - rt_dissim) %>%
  mutate(avg_acc = mean(acc)) %>%
  mutate(rt_acc_sim = mean(RT[acc == 1 & similar == "similar"])) %>%
  mutate(rt_acc_dissim = mean(RT[acc == 1 & similar == "dissimilar"]))%>%
  mutate(rt_inacc_sim = mean(RT[acc == 0 & similar == "similar"])) %>%
  mutate(rt_inacc_dissim = mean(RT[acc == 0 & similar == "dissimilar"]))
```

```{r, echo=FALSE}
ggplot(aes(x = rt_acc_diff), 
       data = d_filt_rt_id) +
  geom_density(alpha = 0.7, adjust = 1.5)

ggplot(aes(x = rt_sim_diff), 
       data = d_filt_rt_id) +
  geom_density(alpha = 0.7, adjust = 1.5)
```

Doing some post-hoc analyses to further explore the relation between children's response latencies and accuracy.

Correlate overall accuracy with RT acc and sim differentials; rts for acc/sim, inacc/sim, acc/dissim, inacc/dissim.

```{r}
d_filt_rt_id <- d_filt_rt_id %>%
  select(ID, avg_acc, rt_acc_diff, rt_sim_diff, rt_acc_sim, rt_acc_dissim, rt_inacc_sim, rt_inacc_dissim) %>%
  distinct %>%
  ungroup %>%
  select(-ID)

rt_corr <- rcorr(as.matrix(d_filt_rt_id), type = "pearson")
rt_corr
rt_corr_n <- sqrt(length(rt_corr$P)) - 1

p.adjust(rt_corr$P[2:rt_corr_n], method = "bonferroni", n = rt_corr_n)

#p.adjust.methods
# c("holm", "hochberg", "hommel", "bonferroni", "BH", "BY",
#   "fdr", "none")
```

```{r, include = FALSE}
corstarsl <- function(x){ 
  require(Hmisc) 
  x <- as.matrix(x) 
  R <- rcorr(x)$r 
  p <- rcorr(x)$P 
  
  ## define notions for significance levels; spacing is important.
  mystars <- ifelse(p < .001, "***", ifelse(p < .01, "** ", ifelse(p < .05, "* ", " ")))
  
  ## trunctuate the matrix that holds the correlations to two decimal
  R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1] 
  
  ## build a new matrix that includes the correlations with their apropriate stars 
  Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x)) 
  diag(Rnew) <- paste(diag(R), " ", sep="") 
  rownames(Rnew) <- colnames(x) 
  colnames(Rnew) <- paste(colnames(x), "", sep="") 
  
  ## remove upper triangle
  Rnew <- as.matrix(Rnew)
  Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
  Rnew <- as.data.frame(Rnew) 
  
  ## remove last column and return the matrix (which is now a data frame)
  Rnew <- cbind(Rnew[1:length(Rnew)-1])
  return(Rnew) 
}
```

Correlation matrix for individual differences in transitions differentials and accuracy.
```{r}
corstarsl(d_filt_rt_id)
```

We conducted exploratory analyses to investigate patterns of responding that might predict overall accuracy. We examined Pearson's *r*s for overall accuracy correlated with a total of six measures: RT differentials based on similarity and accuracy (i.e., RT for similar - similar; RT for inaccurate - RT for accurate), and RTs for each trial type crossing accuracy with similarity (i.e., similar-accurate, similar-inaccurate, dissimilar-accurate, dissimilar-inaccurate). 

We found that children's overall accuracy scores were significantly positively correlated with response latencies for similar trials answered correctly (Bonferroni adjusted *p* = `r round(p.adjust(rt_corr$P[1:rt_corr_n], method = "bonferroni", n = rt_corr_n)[4], digits = 3)`, but not with any of the other measures (adjusted *p*s >.05)

##Summary of Touchscreen Results

Accuracy was higher for dissimilar items.

Accuracy affected response latency (χ2(1)=`r round(acc_effect$Chisq[2], digits = 2)`, p=`r round(acc_effect$p[1], digits = 2)`)
, such that accuracy (compared to inaccuracy) reduced response latencies by `r round(summary(glm_RT_full)$coefficients[3], digits = 2)` (SE = `r round(summary(glm_RT_full)$coefficients[6], digits = 2)`) milliseconds. Similarity was not a significant predictor, and accuracy and similarity did not interact.

T-tests showed that the effect of similarity was not significant among accurate trials, *t* = `r round(test_acc$statistic, digits = 2)`, *p* = `r round(test_acc$p.value, digits = 2)`, nor was it significant for inaccurate trials, *t* = `r round(test_inacc$statistic, digits = 2)`, *p* = `r round(test_inacc$p.value, digits = 2)`.

Individual differences in RT differentials (i.e., RT for similar - similar; RT for inacc - acc) were correlated with each other but not with accuracy. This is expected as accuracy and similarity are correlated. 

# Drift Diffusion Analysis

Workflow taken from Nordmeyer et al. (2016). The goal is to estimate parameters separately for each participant and then we aggregate across participants to get means & confidence intervals on the parameters.

The parameters of the drift drift diffusion model are: 

* $\alpha$ = boundary separation: speed-accuracy tradeoff (higher values mean higher accuracy)
* $\beta$ = initial bias
* $\delta$ = drift rate: speed of information processing (close to zero means ambiguous information)
* $\tau$ = nondecision time: motor response time

Note: need to change input such that Bias is not measuring precognition! 

## Estimating parameters

```{r setuppars}
# get the data we care about and format for Rwiener functions
# columns need to be named "q" for RT and "resp" for response
d_ddm <- d_filt_rt %>% 
  filter(RT <= 6000, RT >= 600) %>% 
  mutate(RT_sec = RT / 1000) %>% 
  select(ID, similar, RT_sec, acc, response) %>% 
  dplyr::rename(q = RT_sec)

d_ddm$acc <- as.factor(d_ddm$acc)
levels(d_ddm$acc) <- list(lower="0", upper="1")

d_ddm <- d_ddm %>% mutate(resp = acc)
```

```{r}
sub.pars <- data.frame(Separation = numeric(),
                       Non.Decision = numeric(),
                       Bias = numeric(),
                       Drift = numeric(),
                       Similar = character(),
                       Sub.Num = character(),
                       stringsAsFactors = F)

#because RWiener is finicky:
d_ddm$resp <- as.character(d_ddm$resp)
```

```{r estpars, include=FALSE}
conditions <- unique(as.character(d_ddm$similar))
subs <- unique(as.character(d_ddm$ID)) 
sub.pars.final <- data.frame()

for (j in 1:length(subs)) {
  sid <- as.character(subs[j]) 
  print(sid)
  dat <- as.data.frame(filter(d_ddm, ID == sid))
    # fit ddm for each participant
    # and for each condition run
  for (cond in 1:length(conditions)) {
    dat_cond <- filter(dat, similar == conditions[cond])
    condition_type <- conditions[cond]
    print(condition_type)
    opt <- optim(c(1, .1, .1, 1), wiener_deviance, 
              dat=select(dat_cond, c(q, resp)), method="Nelder-Mead")
    pars <- c(opt$par, condition_type, sid)
    sub.pars[cond,] <- pars
  }
  sub.pars.final <- rbind(sub.pars.final, sub.pars)  
} 
```

### Plot Parameters

This plot shows the mean parameter values & 95% C.I.s for each stimuli type

```{r plotpars, fig.width=8, fig.height=6, echo=FALSE}
sub.pars.final$Separation <- as.numeric(sub.pars.final$Separation)
sub.pars.final$Non.Decision <- as.numeric(sub.pars.final$Non.Decision)
sub.pars.final$Bias <- as.numeric(sub.pars.final$Bias)
sub.pars.final$Drift <- as.numeric(sub.pars.final$Drift)

sub.pars.final <- sub.pars.final %>% 
  group_by(Similar) %>%
  filter(Separation < mean(Separation) + 3 * sd(Separation), 
         Separation > mean(Separation) - 3 * sd(Separation)) %>%
  filter(Non.Decision < mean(Non.Decision) + 3 * sd(Non.Decision), 
         Non.Decision > mean(Non.Decision) - 3 * sd(Non.Decision)) %>%
  filter(Bias < mean(Bias) + 3 * sd(Bias), 
         Bias > mean(Bias) - 3 * sd(Bias)) %>%
  filter(Drift < mean(Drift) + 3 * sd(Drift), 
         Drift > mean(Drift) - 3 * sd(Drift)) %>%
  ungroup() %>%
  na.omit()

sub.pars.final <- sub.pars.final %>%  gather(Param, Value, Separation:Drift)
```

Plot distributions of parameters across conditions

```{r, echo=FALSE}
ggplot(aes(x = Value, fill = Similar), 
       data = filter(sub.pars.final, Param %in% c("Drift", "Separation"))) +
  geom_density(alpha = 0.7, adjust = 1.5) + 
  facet_grid(.~Param, scales = "free") +
  scale_fill_solarized()
```

Get means and CIs for parameter values and plot.

```{r}
sub.pars.ms <- sub.pars.final %>%
  group_by(Similar, Param) %>%
  multi_boot_standard(column = "Value", empirical_function = "mean")

ggplot(aes(x = Similar, y = mean, fill = Similar), 
       data = filter(sub.pars.ms)) +
  geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  facet_wrap(~Param, scales = "free") +
  scale_fill_solarized() + 
  ylab("Mean Param Value") +
  guides(fill = F) 
```